# 第二讲 轻松玩转书生·浦语大模型趣味Demo

## 一、前置知识

### 1. 大模型
大型语言模型具有许多显著的特点，其中一些主要的包括：
- 巨大的模型规模： 大型语言模型通常拥有数十亿或数千亿个参数，甚至更多。这些庞大的模型规模使得它们能够捕获更多的语义和上下文信息，从而提高了其在各种自然语言处理任务上的性能。
- 丰富的语义理解： 由于其大规模和预训练的特性，大型语言模型能够理解更丰富和复杂的语义信息。它们可以对文本中的词汇、句法和语义进行深入的分析和理解，从而提供更加准确和准确的自然语言处理结果。
- 广泛的适应性： 大型语言模型通常具有广泛的适应性，能够应用于各种自然语言处理任务，如文本分类、命名实体识别、语言生成等。它们可以通过微调或迁移学习来适应不同领域和任务的需求。
- 强大的生成能力： 大型语言模型具有强大的文本生成能力，能够根据给定的上下文生成连贯、合理和语义丰富的文本。这使得它们在对话系统、自动摘要、文本生成等任务中表现出色。
- 可持续的学习和更新： 一些大型语言模型具有在线学习和增量更新的能力，可以随着时间推移不断学习新的知识和语言模式，并持续改进其性能和效果。
- 高计算资源需求： 由于其巨大的模型规模和复杂的结构，大型语言模型通常需要大量的计算资源来进行训练和推断。这使得其在实际应用中可能面临着计算成本高昂的挑战。
- 数据隐私和伦理问题： 由于大型语言模型需要大量的数据来进行训练，因此涉及到用户数据隐私和伦理问题。模型可能会在训练过程中捕获和存储大量的用户信息，这引发了对数据隐私和伦理道德的担忧。
这些特点使得大型语言模型成为自然语言处理领域的重要研究和应用对象，同时也带来了一系列挑战和问题需要解决。

### 2. InternLM 模型全链条开源
<p>InternLM 是一个开源的轻量级训练框架，旨在支持大模型训练而无需大量的依赖。基于InternLM训练框架，上海人工智能实验室已经发布了两个开源的预训练模型:InternLM-7B 和 InternLM-20B。</p>
<p>Lagent 是一个轻量级、开源的基于大语言模型的智能体(agent)框架，用户可以快速地将一个大语言模型转变为多种类型的智能体。通过 Lagent 框架可以更好的发挥 InternLM 模型的全部性能。</p>
<p>浦语·灵笔是基于书生·浦语大语言模型研发的视觉·语言大模型，有着出色的图文理解和创作能力，使用浦语·灵笔大模型可以轻松的创作一篇图文推文。</p>


### 3. InternLM-chat-7B 智能对话 Demo
<p>通过单一的代码库，InternLM 支持在拥有数千个 GPU 的大型集群上进行预训练，并在单个 GPU 上进行微调，同时实现了卓越的性能优化。在 1024 个 GPU 上训练时，InternLM 可以实现近 90% 的加速效率。
InternLM-78 包含了一个拥有 70 亿参数的基础模型和一个为实际场景量身定制的对话模型。该模型具有以下特点:</p>

- 利用数万亿的高质量 token 进行训练，建立了一个强大的知识库;
- 支持 8k token 的上下文窗口长度，使得输入序列更长并增强了推理能力;


### 3. Lagent 智能体工具调用
<p>Lagent 是一个轻量级、开源的基于大语言模型的智能体(agent)框架，用户可以快速地将一个大语言模型转变为多种类型的智能体，并提供了一些典型工具为大语言模型赋能。架构如图所示：</p>
<img src="../Pics/02/Lagent.png" alt="图 1 Lagent架构" style="width: 60%;">
